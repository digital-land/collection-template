name: Run collection
on:
  workflow_call:
    secrets:
      DLB_BOT_EMAIL:
        required: true
      DLB_BOT_TOKEN:
        required: true
      DLB_BOT_EMAIL:
        required: true
      AWS_S3_ACCESS_KEY_ID:
        required: true
      AWS_S3_ACCESS_KEY:
        required: true
env:
  DLB_BOT_EMAIL: ${{ secrets.DLB_BOT_EMAIL }}
  DLB_BOT_TOKEN: ${{ secrets.DLB_BOT_TOKEN }}
  DLB_BOT_USERNAME: ${{ secrets.DLB_BOT_USERNAME }}
jobs:
  build:
    runs-on: ubuntu-latest
    steps:

    - name: Free up disk space
      run: |
        df -h
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        echo
        df -h

    - uses: actions/checkout@v2

    - uses: actions/setup-python@v2
      with:
        python-version: 3.8

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{secrets.AWS_S3_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{secrets.AWS_S3_SECRET_ACCESS_KEY}}
        aws-region: eu-west-2

    - name: Configure git
      run: |
        git config user.email "${DLB_BOT_EMAIL}"
        git config user.name "${DLB_BOT_USERNAME}"
        git remote set-url origin https://${DLB_BOT_USERNAME}:${DLB_BOT_TOKEN}@github.com/${GITHUB_REPOSITORY}.git
        git checkout ${GITHUB_REF##*/}

    - name: Update makerules
      run: make makerules

    - name: Commit updated makerules
      run: make commit-makerules

    - name: Install dependencies
      run: make init

    - name: Run the collector
      run: make collect

    - name: Commit collection logs
      run: make commit-collection

    - name: Save collected resources to S3
      run: make save-resources

    - name: Build the collection database
      run: make collection

    - name: Push collection database to S3
      run: make save-collection

    - name: transform collected files
      run: make transformed

    - name: Save transformed files to S3
      run: make save-transformed

    - name: Build datasets from the transformed files
      run: make dataset

    - name: Save datasets to S3
      run: make save-dataset
    
    - name: Save expectations to S3
      if: always()
      run: make save-expectations

  check-pipeline-errors:
    runs-on: ubuntu-latest
    needs:
      - build
    if: always() && contains(join(needs.*.result, ','), 'failure')
    steps:
      - name: send failure notification
        uses: slackapi/slack-github-action@v1
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'dl-developers'
          payload: |
            {
              "text": "Collection Run: {{ github.repository }}",
              "icon_emoji": ":alert:",
              "username": "CollectionRunner",
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "Collection Run Failed: {{ github.repository }} "
                  }
                },
                {
                  "type": "divider"
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "The report for this scan is available on <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|GitHub>"
                  }
                }
              ]
            }
